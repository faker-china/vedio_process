import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin
import time
import random
from PIL import Image
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor

# ä»£ç†è®¾ç½®ï¼Œæ·»åŠ äº†ç«¯å£
USE_PROXY = True  # è®¾ç½®æ˜¯å¦ä½¿ç”¨ä»£ç†
PROXY = {
    "http": "http://127.0.0.1:7890",  # æ›¿æ¢ä¸ºä½ çš„ä»£ç†åœ°å€å’Œç«¯å£
    "https": "http://127.0.0.1:7890",  # æ›¿æ¢ä¸ºä½ çš„ä»£ç†åœ°å€å’Œç«¯å£
}


# é€šç”¨çš„å›¾ç‰‡æŠ“å–å‡½æ•°
def get_image_urls(url):
    """
    è·å–ç½‘é¡µä¸­æ‰€æœ‰å›¾ç‰‡çš„ URLã€‚
    å¦‚æœé¡µé¢æ˜¯åŠ¨æ€åŠ è½½çš„ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ Requests-HTML æˆ– Selenium è¿›è¡Œæ¸²æŸ“ã€‚
    """
    headers = {
        "User-Agent": random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/89.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.64 Safari/537.36"
        ])
    }

    # ä½¿ç”¨ä»£ç†
    proxies = PROXY if USE_PROXY else None

    # è¯·æ±‚ç½‘é¡µå†…å®¹
    response = requests.get(url, headers=headers, proxies=proxies)
    if response.status_code != 200:
        print(f"âŒ é¡µé¢åŠ è½½å¤±è´¥: {url}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")

    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡çš„ src å±æ€§
    img_tags = soup.find_all("img")
    img_urls = [img["src"] for img in img_tags if "src" in img.attrs]

    # å¤„ç†ç›¸å¯¹è·¯å¾„
    img_urls = [urljoin(url, img_url) for img_url in img_urls]

    return img_urls


# åˆ¤æ–­å›¾ç‰‡ç±»å‹
def get_image_extension(img_url):
    """
    åˆ¤æ–­å›¾ç‰‡ç±»å‹ã€‚
    """
    try:
        response = requests.get(img_url, stream=True, proxies=PROXY if USE_PROXY else None)
        if response.status_code == 200:
            content_type = response.headers.get("Content-Type", "")
            if "image" in content_type:
                img = Image.open(BytesIO(response.content))
                return img.format.lower()  # è¿”å›å›¾ç‰‡æ ¼å¼ (jpg, png, gif ç­‰)
    except Exception as e:
        print(f"âŒ è·å–å›¾ç‰‡æ ¼å¼é”™è¯¯: {e}")
    return None


# ä¸‹è½½å•å¼ å›¾ç‰‡
def download_image(img_url, output_dir, retries=3):
    """
    ä¸‹è½½å•å¼ å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°ã€‚
    """
    try:
        # è·å–å›¾ç‰‡æ ¼å¼
        img_extension = get_image_extension(img_url)
        if img_extension:
            img_name = os.path.join(output_dir, f"{random.randint(1000, 9999)}.{img_extension}")

            for attempt in range(retries):
                try:
                    response = requests.get(img_url, stream=True, proxies=PROXY if USE_PROXY else None)
                    if response.status_code == 200:
                        with open(img_name, "wb") as f:
                            f.write(response.content)
                        print(f"âœ… ä¸‹è½½æˆåŠŸ: {img_name}")
                        break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                    else:
                        print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {img_url}")
                        break
                except Exception as e:
                    print(f"âŒ è¯·æ±‚é”™è¯¯ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•: {e}")
                    time.sleep(2)  # é‡è¯•å‰ç­‰å¾…
        else:
            print(f"âš ï¸ æ— æ³•ç¡®å®šå›¾ç‰‡æ ¼å¼: {img_url}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å›¾ç‰‡é”™è¯¯: {e}")


# ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
def download_images(image_urls, output_dir):
    """
    ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ï¼Œå¹¶ä½¿ç”¨çº¿ç¨‹æ± åŠ é€Ÿä¸‹è½½ã€‚
    """
    max_threads = min(20, len(image_urls))  # æ ¹æ®å›¾ç‰‡æ•°é‡è°ƒæ•´çº¿ç¨‹æ•°
    os.makedirs(output_dir, exist_ok=True)  # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨

    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        for img_url in image_urls:
            executor.submit(download_image, img_url, output_dir)

    print("ğŸ‰ æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆï¼")


# ä¸»ç¨‹åº
def main(url, output_dir):
    """
    ä¸»ç¨‹åºï¼šæŠ“å–ç½‘é¡µä¸­çš„æ‰€æœ‰å›¾ç‰‡å¹¶ä¸‹è½½ã€‚
    """
    print("ğŸš€ å¼€å§‹æŠ“å–ç½‘é¡µä¸­çš„å›¾ç‰‡...")
    image_urls = get_image_urls(url)
    if image_urls:
        print(f"ğŸ¯ æ‰¾åˆ° {len(image_urls)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹ä¸‹è½½...")
        download_images(image_urls, output_dir)
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼Œæˆ–è€…é¡µé¢åŠ è½½å¤±è´¥")


# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    URL = "https://x.com/xiaoqing6666/media"  # ç›®æ ‡ç½‘ç«™ URL
    OUTPUT_DIR = r"D:\ç´ èœåº“\youtube\image\X\æ–°å»ºæ–‡ä»¶å¤¹"  # æœ¬åœ°ä¿å­˜ç›®å½•
    main(URL, OUTPUT_DIR)
