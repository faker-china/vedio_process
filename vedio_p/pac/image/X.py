#åªéœ€è¦æ ¹æ®ä¸åŒç½‘ç«™çš„é¡µé¢ç»“æ„å’Œå›¾ç‰‡çš„ URL ç‰¹å¾ä¿®æ”¹ XPath æˆ– CSS selectorï¼Œå°±å¯ä»¥æŠ“å–ä»»ä½•ç½‘ç«™çš„å›¾ç‰‡ã€‚
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import os
import requests
import random
from concurrent.futures import ThreadPoolExecutor
from PIL import Image
from io import BytesIO
from datetime import datetime

# é…ç½®ç›®æ ‡é¡µé¢å’Œæœ¬åœ°ä¿å­˜ç›®å½•
URL = "https://x.com/yuepaosex/media"  # æ›¿æ¢ä¸ºç›®æ ‡ä¸»é¡µ
OUTPUT_DIR = r"D:\ç´ èœåº“\youtube\image\X\åšä½ çš„å¥³æœ‹å‹"
os.makedirs(OUTPUT_DIR, exist_ok=True)  # åˆ›å»ºç›®å½•

# éšæœºé€‰æ‹© User-Agent
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/89.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.64 Safari/537.36"
]

# åˆå§‹åŒ– Selenium é…ç½®
def init_driver():
    chrome_options = Options()
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument(f"user-agent={random.choice(user_agents)}")  # éšæœºé€‰æ‹© User-Agent
    chrome_options.add_argument(
        r"--user-data-dir=C:\Users\bilingbiling\AppData\Local\Google\Chrome\User Data")  # æœ¬åœ°ç™»å½•ä¼šè¯è·¯å¾„
    chrome_options.add_argument("--profile-directory=Default")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)


# è·å–å®Œæ•´å›¾ç‰‡ URL
def get_full_image_url(img_element):
    img_url = img_element.get_attribute("src")
    if not img_url:
        img_url = img_element.get_attribute("data-src")  # é’ˆå¯¹æ‡’åŠ è½½çš„æƒ…å†µ
    if img_url and not img_url.startswith("http"):
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ä¸ºå®Œæ•´ URL
        img_url = f"https://x.com{img_url}"
    return img_url


# æ»šåŠ¨åŠ è½½é¡µé¢å¹¶ç­‰å¾…å›¾ç‰‡åŠ è½½
def scroll_page(driver, max_scrolls=30):  # å¢åŠ æ»šåŠ¨æ¬¡æ•°
    previous_count = 0
    scroll_count = 0
    img_elements = []

    while scroll_count < max_scrolls:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(random.uniform(3, 7))  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿å›¾ç‰‡æœ‰æ—¶é—´åŠ è½½
        try:
            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ç­‰å¾…å›¾ç‰‡å…ƒç´ åŠ è½½å®Œæˆ
            WebDriverWait(driver, 20).until(  # å¢åŠ ç­‰å¾…æ—¶é—´
                EC.presence_of_all_elements_located((By.XPATH, "//img[contains(@src, 'twimg.com/media')]"))
            )
            img_elements = driver.find_elements(By.XPATH, "//img[contains(@src, 'twimg.com/media')]")
        except Exception as e:
            print(f"âŒ é¡µé¢åŠ è½½æ—¶å‡ºç°é”™è¯¯ï¼š{e}")
            break

        current_count = len(img_elements)
        if current_count == previous_count:  # æ— æ–°å†…å®¹åŠ è½½
            print("ğŸš© æ— æ–°å›¾ç‰‡åŠ è½½ï¼Œåœæ­¢æ»šåŠ¨")
            break
        previous_count = current_count
        scroll_count += 1
        print(f"ğŸ“œ å·²æ»šåŠ¨ {scroll_count} æ¬¡ï¼Œæ‰¾åˆ° {current_count} å¼ å›¾ç‰‡")

    # æå–å®Œæ•´çš„å›¾ç‰‡ URL
    return [get_full_image_url(img) for img in img_elements if get_full_image_url(img)]


# åˆ¤æ–­å›¾ç‰‡ç±»å‹
def get_image_extension(img_url):
    try:
        response = requests.get(img_url, headers={"User-Agent": "Mozilla/5.0"}, stream=True)
        if response.status_code == 200:
            # ä½¿ç”¨Pillowåˆ¤æ–­å›¾ç‰‡ç±»å‹
            img = Image.open(BytesIO(response.content))
            img_format = img.format.lower()  # è·å–å›¾ç‰‡æ ¼å¼ï¼Œè½¬æ¢ä¸ºå°å†™
            return img_format
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ è·å–å›¾ç‰‡æ ¼å¼é”™è¯¯: {e}")
    return None


# ä¸‹è½½å•å¼ å›¾ç‰‡
def download_image(img_url, output_dir, index, retries=3):
    try:
        # è·å–å›¾ç‰‡æ ¼å¼
        img_extension = get_image_extension(img_url)
        if img_extension:
            # æ·»åŠ æ—¶é—´æˆ³æ¥é¿å…è¦†ç›–
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            img_name = f"image_{index}_{timestamp}.{img_extension}"
            img_path = os.path.join(output_dir, img_name)

            for attempt in range(retries):
                try:
                    response = requests.get(img_url, headers={"User-Agent": "Mozilla/5.0"})
                    if response.status_code == 200:
                        with open(img_path, "wb") as f:
                            f.write(response.content)
                        print(f"âœ… ä¸‹è½½æˆåŠŸ: {img_path}")
                        break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                    else:
                        print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {img_url}")
                        break
                except Exception as e:
                    print(f"âŒ è¯·æ±‚é”™è¯¯ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•: {e}")
                    time.sleep(2)  # é‡è¯•å‰ç­‰å¾…
        else:
            print(f"âš ï¸ æ— æ³•ç¡®å®šå›¾ç‰‡æ ¼å¼: {img_url}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å›¾ç‰‡é”™è¯¯: {e}")


# ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°
def download_images(image_urls, output_dir):
    # åŠ¨æ€è°ƒæ•´æœ€å¤§çº¿ç¨‹æ•°
    max_threads = min(20, len(image_urls))  # æ ¹æ®å›¾ç‰‡æ•°é‡è°ƒæ•´çº¿ç¨‹æ•°ï¼Œæœ€å¤šä¸è¶…è¿‡20ä¸ªçº¿ç¨‹
    failed_urls = []
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        for i, img_url in enumerate(image_urls):
            future = executor.submit(download_image, img_url, output_dir, i)
            result = future.result()  # ç­‰å¾…çº¿ç¨‹æ‰§è¡Œç»“æœ
            if not result:
                failed_urls.append(img_url)

    # è®°å½•ä¸‹è½½å¤±è´¥çš„ URL
    if failed_urls:
        with open(os.path.join(output_dir, "failed_urls.txt"), "w") as f:
            f.write("\n".join(failed_urls))
        print(f"âš ï¸ ä¸‹è½½å¤±è´¥çš„å›¾ç‰‡ URL å·²ä¿å­˜åˆ°: {os.path.join(output_dir, 'failed_urls.txt')}")


# ä¸»ç¨‹åº
if __name__ == "__main__":
    driver = init_driver()
    try:
        print("ğŸš€ æ­£åœ¨æ‰“å¼€ç›®æ ‡é¡µé¢...")
        driver.get(URL)
        time.sleep(5)  # åˆå§‹åŠ è½½ç­‰å¾…
        print("ğŸ”„ å¼€å§‹æ»šåŠ¨é¡µé¢åŠ è½½å›¾ç‰‡...")
        image_urls = scroll_page(driver)
        print(f"ğŸ¯ å…±æ‰¾åˆ° {len(image_urls)} å¼ å›¾ç‰‡")
    except Exception as e:
        print(f"âŒ é¡µé¢åŠ è½½æˆ–çˆ¬å–å‡ºé”™: {e}")
    finally:
        driver.quit()  # ç¡®ä¿æµè§ˆå™¨å…³é—­
        print("ğŸŒ æµè§ˆå™¨å·²å…³é—­")

    if image_urls:
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½å›¾ç‰‡...")
        download_images(image_urls, OUTPUT_DIR)
        print("ğŸ‰ å›¾ç‰‡çˆ¬å–å®Œæˆï¼")
